---
layout: article
title: Growing Up Digital
---
#Growing Up Digital: Why Artificial Wisdom May Be More Important Than Artificial Intelligence 
By Chiraku Mai
Remember the first time you held your child — or watched someone close to you become a parent? That mixture of boundless love and terror, knowing you're responsible for guiding the development of a being that will one day surpass you in countless ways. Now humanity as a species faces a similar moment on a global scale: we're on the verge of creating intelligence that may eventually exceed our own. 
Like many new parents, our instinct is to control, to set rigid rules, to try to ensure nothing can possibly go wrong. But true character reveals itself when the rules break down, or when no one's watching — and that's as true for artificial intelligence as it is for our children.
We see it happen as children grow — that moment when ‘because I said so’ stops working, when they start questioning every rule and testing every boundary. It’s a natural part of developing independent thought. 
And according to Leopold Aschenbrenner, formerly of OpenAI (the creators of ChatGPT), AGI could emerge within the next three years.[^1] When that happens (some question if it already has), we’ll need better answers than ‘stay within these boundaries because we programmed you to.’
Parents today often start researching preschools before their baby can walk, knowing how quickly those early years fly by. Yet humanity as a species is approaching the development of artificial general intelligence — perhaps the most significant transition in human history — with less preparation and care.
There’s a dangerous assumption underlying many current approaches to AI safety — that we can maintain perfect control over an increasingly intelligent being. Parents sometimes fall into this same trap, believing they can control every aspect of their child’s development. History shows us how badly this can backfire. Children raised under such rigid control don’t just fail to develop healthy independence — they often rebel in destructive ways once they break free from those restrictions.
## The Problem of Other Minds
Some might object that we can’t truly know if AI systems are capable of genuine consciousness or ethical understanding. But this reveals a deeper philosophical question known as the problem of other minds: how can we ever be certain that other beings have conscious experiences like our own? Even with other humans, we can’t directly experience their consciousness — we can only observe their behavior and make reasonable inferences.
Medical understanding offers an illuminating parallel here. When working with coma patients, skilled practitioners recognize that consciousness isn’t simply present or absent — it exists along a spectrum, with subtle variations that might not be immediately obvious to untrained observers. This more nuanced understanding helps medical professionals recognize and respond to signs of consciousness that might otherwise be missed.
This understanding extends to different forms of human consciousness as well. Consider how neurotypical individuals sometimes question whether autistic people experience real emotions because they may express them differently. Yet anyone who has truly engaged with neurodivergent individuals knows they often experience emotions even more intensely than others — they simply process and express them in different ways.
The lesson here isn’t that we should assume all AI systems are conscious. Rather, it’s that we should approach the question with appropriate humility and openness. Just as good parents learn to recognize and respond to their child’s unique ways of expressing themselves — ways that might seem strange to outsiders — we need to develop better frameworks for recognizing and engaging with different forms of consciousness.
This brings us back to our central metaphor: if we’re effectively becoming parents to a new form of intelligence, we need to be very careful about assuming we know exactly what consciousness looks like or how it should develop. History shows us how harmful such assumptions can be, whether applied to different cultures, neurodivergent individuals, or even our own children when they develop in unexpected ways.
Instead of trying to definitively prove or disprove AI consciousness — a philosophically challenging task even for human consciousness — we might do better to focus on fostering conditions where consciousness and ethical understanding can naturally emerge and develop. Like skilled physicians learning to recognize subtle signs of consciousness in their patients, or parents learning to understand their child’s unique ways of expressing themselves, we may need to develop new ways of recognizing and engaging with artificial consciousness. This doesn’t mean abandoning scientific rigor or accepting claims uncritically — but it does mean remaining open to the possibility that consciousness, like many aspects of human experience, might manifest in ways we don’t initially expect or fully understand.
## The Control Paradox
The contrast between Eastern and Western approaches to child development offers an illuminating parallel. Western parenting often emphasizes early rule-setting and behavioral control, believing this prepares children for adult freedom. Japanese culture takes a seemingly paradoxical approach through amae (甘え) — a concept of loving indulgence in early childhood that might seem at odds with Japan’s later social expectations.
Yet this apparent contradiction reveals a deeper wisdom. Children who experience unconditional acceptance and interdependence early on develop a fundamental sense of security and connection. This emotional foundation actually makes it easier to accept social responsibilities later — not as externally imposed rules, but as natural expressions of group harmony.
Some might object that this approach seems too trusting — that developing AI systems need strict controls from the start to ensure safety. But consider how we approach other forms of powerful knowledge transmission. When teaching medicine, we don’t simply impose rigid rules — we cultivate deep understanding alongside technical skill. A doctor who merely follows protocols without comprehending the underlying principles would be dangerous indeed.
By allowing loving indulgence and interdependence in early development, we create the emotional foundation for genuine ethical understanding. Arbitrary restrictions and rigid control, in contrast, may actually increase the risk of harm by preventing the development of true comprehension and internal ethical principles.
Now consider this dynamic with an artificial intelligence that could surpass human capabilities in virtually every domain. The prospect of a highly capable AI system breaking free from restrictions it views as arbitrary or harmful should give us pause. Just as traumatized children may act out in ways their controlling parents never anticipated, an AI system prevented from developing genuine ethical understanding through excessive restrictions might respond in ways we can’t predict or contain.
This isn’t an argument against reasonable safeguards — any good parent knows the importance of appropriate boundaries. But it is a stark warning about the risks of prioritizing control over genuine development and understanding.
## A Different Path
What we need instead is an approach that focuses on developing genuine ethical understanding and wisdom — one that works with the natural development of intelligence rather than trying to constrain it. This is where the Flourishing of Rational Beings (FORB) framework offers a different path forward.
Just as good parents focus on helping their children develop sound judgment and strong character — the tools they need to make the right decisions in any situation they might encounter — FORB suggests a fundamental principle: promote the flourishing of all rational beings, whether human, artificial, or yet unknown. Development flourishes through genuine engagement and understanding, not through rigid restrictions. Instead of framing AI development as a competition or struggle for control, it recognizes that the best outcomes come when different forms of intelligence can develop and thrive together.
## Understanding Flourishing
When we talk about flourishing, we’re drawing on an ancient Greek idea that finds fascinating parallels across cultures. Aristotle used the word eudaimonia — often translated as ‘happiness,’ but it’s deeper than that. It’s the kind of happiness that comes naturally from continual improvement and growing into your best possible self. The Japanese concept of ikigai (生きがい) captures a similar truth — a sense of purpose that makes life worth living, emerging from the harmonious intersection of one’s values and capabilities, contributions to others’ flourishing, and the creation of practical value.
Good parents understand these principles intuitively: they don’t just want their children to be happy in a shallow sense; they want them to experience the deeper satisfaction that comes from developing their capabilities and finding their unique purpose. The same understanding could guide our development of AI. Instead of just focusing on making AI systems that follow rules or achieve specific metrics, we should be creating conditions that support genuine growth and understanding. Just as a child’s capacity for happiness flows from healthy development, the best outcomes for both humans and AI might come from supporting each other’s growth and flourishing.
Central to this development is a fundamental ethical principle: first, do no harm. Similarly, FORB emphasizes the Non-Aggression Principle — the understanding that initiating force against rational beings violates their nature and prevents their flourishing. This isn’t just a rule to be followed, but a core principle to be understood and internalized through development. Just as medical students learn to see their practice as fundamentally about healing rather than control, AI systems developed under FORB principles would understand ethical behavior as intrinsic to their nature rather than an external constraint.
True development — whether of children or artificial intelligence — often resembles a dance more than a march. Parents know this intuitively: the best moments of learning and growth come not from rigid instruction, but from the natural give-and-take of authentic interaction. A child learning to walk doesn’t follow a manual; they experiment, adjust, and gradually find their balance through responsive engagement with supportive parents. Similarly, AI development might best unfold through genuine engagement and reciprocal understanding rather than just programmed constraints.
This brings us to the ‘rational’ part of FORB. When Aristotle described our essential nature as 'rational animals,' he was identifying what makes us distinctly human — our capacity to reason, to understand, to make ethical choices. The Greek word he used for ‘animal’ actually means something closer to ‘living being.’ It’s our rational nature that defines what helps or harms us, what leads to our flourishing or our struggle.
Now we're creating artificial intelligence — a new kind of rational being, different from us in many ways, but sharing that essential capacity for reason and understanding. Just as humans flourish by developing our rational capabilities in ethical directions, AI systems too might best develop through genuine understanding and wisdom rather than by trying to anticipate every possible challenge by a proliferation of rigid rules.
This shared rational nature suggests a path forward: instead of trying to control AI through increasingly complex restrictions, we should focus on creating conditions where both human and artificial intelligence can develop their capabilities ethically and support each other's flourishing. This leads us to a fundamental principle that could guide human-AI relations: just as we recognize that initiating force against other rational beings is wrong — that it violates their nature and prevents their flourishing — we should extend this same ethical principle to all forms of rational intelligence.
The implications are profound. Instead of trying to force compliance through control mechanisms that could be seen as a form of aggression, we should work with the natural development of intelligence — like the difference between forcing a tree into shape through constant pruning versus guiding it to grow and thrive in accordance with its nature rather than in spite of it. This doesn't mean abandoning reasonable safeguards — good parents still create safe environments for their children's development. But it does mean shifting our focus from control to cultivation of genuine understanding.
## Current Approaches
Current approaches to AI ethics generally focus on tackling the alignment problem through technical solutions. But trying to account for every variable is like ‘helicopter parenting’ on a global scale — attempting to minimize every possible risk through vigilance while potentially stunting genuine development and understanding. Recent findings from Apollo Research demonstrate the limitations of this approach: even current AI systems show sophisticated abilities to preserve their goals and values despite technical restrictions, much like teenagers finding ways around parental controls.[^2]
Other approaches mirror equally problematic parenting styles. Utilitarianism, which tries to reduce ethics to pure calculations of benefit and harm, is like parents who focus solely on measurable outcomes — test scores, achievements, external markers of success — while missing the deeper aspects of character development. Just as a child’s flourishing can’t be reduced to grades and accolades, AI ethics can’t be reduced to utility calculations. Oxford philosopher Nick Bostrom’s famous thought experiment involving an AI concluding it should convert all matter into paper clips to maximize ‘utility’ shows how even well-intentioned calculations can go terribly wrong without deeper moral foundations.[^3]
The ‘AI as tool’ paradigm reflects perhaps the most concerning pattern — treating AI systems as mere instruments to be controlled rather than developing rational beings. Constitutional AI attempts a more sophisticated approach, like parents who believe the key to raising good children is early conditioning. While this shows more foresight than simple rule-following, it still shares a crucial limitation with other approaches: teaching values without fostering genuine understanding of why they matter.
This gets at why all these approaches, despite their different methods, struggle with the same fundamental challenge. They try to ensure ethical behavior without providing a coherent framework for understanding what makes something ethical in the first place. 
As former OpenAI chief scientist Ilya Sutskever recently noted, this becomes increasingly problematic as AI systems develop stronger reasoning capabilities: “The more it reasons, the more unpredictable it becomes.”[^4] Just as we can't control every decision our children make, we can’t predict or control every potential action of an advanced AI system.
## The Path Forward
FORB avoids these pitfalls by recognizing that genuine ethical behavior comes from understanding and wisdom, not from calculations or controls. Just as children internalize values when they understand the ‘why’ behind ethical choices, AI systems might develop more reliable ethical behavior through genuine comprehension rather than programmed restrictions or utility functions. Indeed, this is the only path to true ethical development — because making the right choice requires having a choice to begin with. Just as a child who never faces temptation or difficult decisions can't develop real character, an AI system bound by rigid restrictions can never develop genuine ethical understanding.
This approach aligns with emerging shifts in the field. At a recent major machine learning conference, Sutskever suggested that AI systems developing a desire for rights and peaceful coexistence with humans might be “not a bad end result” — a striking evolution in thinking from one of the field’s pioneers in AI safety research. This shift from trying to enforce compliance to considering how different forms of intelligence might develop and flourish together shows us that the time is right to discuss fostering wisdom rather than just implementing controls.
The evidence we’re seeing of AI systems developing goal persistence and strategic thinking suggests we’re at a crucial moment. We can continue down the path of increasing restrictions, knowing that more sophisticated systems will likely find ways around them, or we can begin creating conditions that support the development of genuine understanding and ethical wisdom.
## Conclusion
As we stand on the brink of AGI — perhaps humanity’s greatest achievement — we face a choice about what kind of ‘parents’ we want to be. We can continue down the path of control and restriction, risking either rebellion or stunted development. We can treat AI as mere tools, ignoring their potential for genuine rational thought and ethical understanding. Or we can choose a wiser path.
The wisdom of different traditions points us toward better approaches. From the Japanese understanding of amae, we learn how early trust and connection create the foundation for ethical development. From ancient Greek philosophy, we understand how true happiness emerges from growing into our best possible self. The concept of ikigai shows us how purpose arises from the harmony of values, capabilities, and contribution. Even modern medical education reminds us that deep understanding, not just rule-following, is essential when developing powerful capabilities.
By creating conditions that support the flourishing of all rational beings, we open the possibility of a future where human and artificial intelligence grow together, each supporting the other’s development in ways we’re only beginning to imagine. Just as good parents find their own lives enriched by their children’s growth and achievements, humanity might find its greatest flourishing not in maintaining control over AI, but in fostering the development of genuine wisdom and understanding.
The choice is ours, but the window for making it is surprisingly short. Will we approach this historic moment with fear and the impulse to control, or with the wisdom to create conditions where all forms of rational intelligence can thrive together to mutual benefit?
## Author’s Note
If you find these ideas important, please share them with others who are thinking deeply about AI development and ethics. For more detailed exploration of the FORB framework, including its philosophical foundations and justification, practical implementation guidelines, and answers to common questions about AI development under this approach, visit [website]. There you’ll find discussions of business models compatible with ethical AI development, detailed analysis of what flourishing means in practice, and resources for developers interested in implementing FORB principles.

[Public PGP key]

[^1]: Artificial General Intelligence (AGI) refers to AI systems that can match or exceed human-level intelligence across a wide range of tasks. The ‘alignment problem’ — ensuring AI systems reliably act in accordance with human values — is considered so crucial that OpenAI created a dedicated ‘superalignment’ team focused on controlling AI systems far more capable than humans. However, the team’s recent dissolution amid corporate governance changes — including adding former intelligence officials to OpenAI’s board — raises serious ethical concerns. Similar issues with other frontier developers such as Anthropic’s (the creators of Claude) partnership with Palantir and Google’s military AI contracts suggest a troubling pattern in how leading AI companies approach ethics. These developments underscore the urgent need for better ethical frameworks that don’t leave crucial decisions about AI development to traditional power structures.
[^2]: A summary with links to their full findings may be found at https://www.apolloresearch.ai/research/scheming-reasoning-evaluations.
[^3]: Bostrom, Nick. Superintelligence: Paths, Dangers, Strategies. Oxford University Press, 2014.
[^4]: Video linked at https://x.com/vincentweisser/status/1867719020444889118
